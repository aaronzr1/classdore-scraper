name: Scrape data, upload to redis, and push (data-pipeline)

on:
  schedule:
    - cron: "30 8 * * *"  # 3:30 AM CT â†’ 8:30 UTC
  workflow_dispatch:
    inputs:
      skip_scrape:
        description: 'Skip scraping step'
        type: boolean
        default: false
      skip_upload:
        description: 'Skip Redis upload step'
        type: boolean
        default: false
      skip_commit:
        description: 'Skip commit and push step'
        type: boolean
        default: false

jobs:
  scrape-data:
    runs-on: ubuntu-latest

    env:
      REDIS_URL: ${{ secrets.REDIS_URL }}

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GH_PAT }} # personal access token with repo write access

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: pip install -r requirements.txt

      - name: Set Git identity
        run: |
          git config user.name "GitHub Actions"
          git config user.email "actions@github.com"

      - name: Merge main into data-pipeline
        run: |
          git fetch origin
          git checkout -B data-pipeline origin/data-pipeline

          # Pull the latest from main, but skip overwriting data/
          git checkout origin/main -- . ':!data/'

          # Commit only if there are changes
          if ! git diff --cached --quiet; then
            git commit -am "Sync main into data-pipeline (preserving data/)"
            git push origin data-pipeline
          else
            echo "No changes to merge"
          fi

      - name: Check for UPLOAD_ONLY marker
        id: check_upload_only
        run: |
          if [ -f "UPLOAD_ONLY" ]; then
            echo "UPLOAD_ONLY exists, skipping -l job."
            echo "skip=true" >> $GITHUB_OUTPUT
          else
            echo "skip=false" >> $GITHUB_OUTPUT
          fi

      - name: Run scraper
        if: steps.check_upload_only.outputs.skip == 'false' && !inputs.skip_scrape
        run: python scraper.py

      - name: Check if data.json has changes
        id: check_data_changes
        run: |
          if git diff --quiet -- data/data.json; then
            echo "No changes detected in data/data.json"
            echo "has_changes=false" >> $GITHUB_OUTPUT
          else
            echo "Changes detected in data/data.json"
            echo "has_changes=true" >> $GITHUB_OUTPUT
          fi

      - name: Upload to Redis
        if: steps.check_data_changes.outputs.has_changes == 'true' && !inputs.skip_upload
        run: python upload_to_redis.py data/data.json

      - name: Commit and push (data-pipeline branch)
        if: ${{ !inputs.skip_commit }}
        run: |
          git add data/course_listings.json
          git add data/data.json
          git commit -m "Automated output for $(date -u +"%Y-%m-%d %H:%M:%S UTC")" || echo "No changes"
          git push origin data-pipeline